<p class="c52"><span class="c51">There&nbsp;</span><span class="c3">will be three evaluation scenarios:</span></p>
<h3 id="h.3rdcrjn" class="c32"><span>Scenario 1:&nbsp;</span><span class="c44">Only plain text is given (Subtasks A, B, C).</span></h3>
<p class="c34"><span>In this first scenario, the participants will perform the three subtasks consecutively and provide the corresponding development output files. The only input provided are plain text files&nbsp;</span><span class="c35">input_&lt;topic&gt;.txt&nbsp;</span><span class="c3">for a particular list of topics that were not released with the training data.</span></p>
<p class="c34"><span>Systems will be ranked according to an aggregated&nbsp;</span><span class="c7">F1</span>&nbsp;<span>metric computed on the three tasks, by considering&nbsp;</span><span class="c7">precision</span>&nbsp;<span>and&nbsp;</span><span class="c7">recall</span>&nbsp;<span class="c3">as follows:</span></p>
<p class="c30"><img src="https://tass18-task3.github.io/website/images/image10.png" alt="" /></p>
<p class="c30"><img src="https://tass18-task3.github.io/website/images/image11.png" alt="" /></p>
<p class="c30"><img src="https://tass18-task3.github.io/website/images/image1.png" alt="" /></p>
<p class="c2"><span class="c3">Besides this aggregated F1 score, individual F1 scores for each of the subtasks will also be reported.</span></p>
<h3 id="h.26in1rg" class="c23"><span>Scenario 2:&nbsp;</span><span class="c44">Plain text and manually annotated key phrase boundaries are given (Subtasks B, C).</span></h3>
<p class="c2"><span>In this second scenario participants will perform tasks B and C sequentially, and provide the corresponding output files. As input, they receive both plain text files (</span>&nbsp;<span class="c35">input_&lt;topic&gt;.txt</span>&nbsp;<span>), and the corresponding gold files for the task A (</span>&nbsp;<span class="c35">output_A_&lt;topic&gt;.txt</span>&nbsp;<span>). The purpose of this scenario is to evaluate the quality of tasks B and C independently from task A. As in the previous scenario, an aggregated&nbsp;</span><span class="c7">F1</span>&nbsp;<span>metric is reported, based on the following&nbsp;</span><span class="c7">precision</span>&nbsp;<span>and&nbsp;</span><span class="c7">recall</span>&nbsp;<span class="c3">:</span></p>
<p class="c30"><img src="https://tass18-task3.github.io/website/images/image12.png" alt="" /></p>
<p class="c30"><img src="https://tass18-task3.github.io/website/images/image13.png" alt="" /></p>
<p class="c30"><img src="https://tass18-task3.github.io/website/images/image1.png" alt="" /></p>
<p class="c34"><span class="c3">Besides the aggregated F1 metric, individual scores of F1 for each of the subtasks are also reported.</span></p>
<h3 id="h.lnxbz9" class="c23"><span>Scenario 3:&nbsp;</span><span class="c44">Plain text with manually annotated key phrases and their types are given (Subtask C).</span></h3>
<p class="c34"><span>In this scenario both the gold outputs for task A and task B are provided, and the participants must only perform the process to obtain task C output files. The purpose of this scenario is to evaluate only the quality of task C independently of the complexity of task A and B. As before, an aggregated F1 metric is reported, based on the following&nbsp;</span><span class="c7">precision</span>&nbsp;<span>and&nbsp;</span><span class="c7">recall</span>&nbsp;<span class="c3">:</span></p>
<p class="c30"><img src="https://tass18-task3.github.io/website/images/image14.png" alt="" /></p>
<p class="c30"><img src="https://tass18-task3.github.io/website/images/image15.png" alt="" /></p>
<p class="c30"><img src="https://tass18-task3.github.io/website/images/image1.png" alt="" /></p>